{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "Importing Libraries\n",
    "'''\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import os\n",
    "import datetime\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "Loading data\n",
    "'''\n",
    "train_df = pd.read_csv('train.csv', encoding = \"ISO-8859-1\") \n",
    "demog_df = pd.read_csv('demog.csv', encoding = \"ISO-8859-1\") \n",
    "submission = pd.read_csv('submission.csv', encoding = \"ISO-8859-1\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df = pd.merge(train_df, demog_df, on='HCP_ID', how='left')\n",
    "#train_df['gender'] = train_df['gender'].fillna('MALE')\n",
    "train_df.drop('HCP_ID', axis=1, inplace =True)\n",
    "#train_df = pd.get_dummies(train_df, ['Region', 'Value', 'gender' ])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Visualizing the distribution of Features of the dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.hist(np.sort(train_df['RL'].dropna().values))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.hist(np.sort(submission['RL'].values))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.hist(np.sort(train_df['OLV'].dropna().values))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.hist(np.sort(submission['OLV'].dropna().values))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.hist(np.sort(train_df['RR'].dropna().values))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.hist(np.sort(submission['RR'].dropna().values))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.hist(np.sort(train_df['DRT'].dropna().values))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.hist(np.sort(submission['DRT'].dropna().values))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.hist(np.sort(train_df['DMS'].dropna().values))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.hist(np.sort(submission['DMS'].dropna().values))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.hist(np.sort(train_df['OLA'].dropna().values))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.hist(np.sort(submission['OLA'].dropna().values))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_number_of_null_entries(df, var):\n",
    "    return df[var].shape[0] - df[var].count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "Number of Null values in every column\n",
    "'''\n",
    "for x in train_df.columns:\n",
    "    print (x, end=\" \")\n",
    "    print (get_number_of_null_entries(train_df, x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.cluster import KMeans\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from math import sqrt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_error(df, columns):\n",
    "    rmse = 0\n",
    "    for x in columns:\n",
    "        y = df[x].dropna()\n",
    "        me = y.mean()\n",
    "        y = df[x].fillna(me)\n",
    "        rmse = rmse + sqrt(sum((y-me)**2))\n",
    "    return rmse"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "l = ['Speciality_ID', 'Age', 'Region_rural', 'Region_urban', 'Value_H', 'Value_L', 'Value_M', 'Value_U', 'gender_FEMALE', 'gender_MALE']\n",
    "columns = ['RL', 'P2P', 'OLV', 'RR', 'DRT', 'DMS', 'OLA', 'DEM']\n",
    "X = train_df[l]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "Formed Clusters using the columns which didnot have Null values.\n",
    "'''\n",
    "error_dict = {}\n",
    "for num_cluster in range(1000, 5000, 100):\n",
    "    k_means = KMeans(n_clusters= num_cluster, max_iter=150)\n",
    "    k_means.fit(X)\n",
    "    labels = k_means.labels_\n",
    "    error = 0\n",
    "    for l in range(num_cluster):\n",
    "        cluster_error = get_error(train_df[columns].iloc[np.where(labels == l)], columns)\n",
    "        error += cluster_error\n",
    "    error_dict[num_cluster] = error/num_cluster"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sorted_by_value_keys = sorted(error_dict, key = error_dict.get, reverse = True)\n",
    "for r in sorted_by_value_keys:\n",
    "    print (r, error_dict[r])\n",
    "    break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "The error was decreasing with increase in the number of clusters. I could'not find optimum number of clusters because it was too much time to run.\n",
    "My final submission is based on clustering with 3000 clusters.\n",
    "'''\n",
    "n_clusters = 3000\n",
    "k_means = KMeans(n_clusters=3000, max_iter=250)\n",
    "k_means.fit(X)\n",
    "labels = k_means.labels_\n",
    "for l in range(n_clusters):\n",
    "    for x in columns:\n",
    "        me = train_df[columns].iloc[np.where(labels == l)][x].mean()\n",
    "        train_df[columns].iloc[np.where(labels == l)][x].replace(-0.1, me)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df['HCP_ID'] = train_df_new['HCP_ID']\n",
    "train_df = train_df[['HCP_ID','RL', 'P2P', 'OLV', 'RR', 'DRT', 'DMS', 'OLA', 'DEM']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df.to_csv('shariq_suhail_03021997.csv', index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
