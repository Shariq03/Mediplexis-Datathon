{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "Importing Libraries\n",
    "'''\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import os\n",
    "import datetime\n",
    "import xgboost as xgb\n",
    "\n",
    "from sklearn.model_selection import train_test_split, GridSearchCV,KFold\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "Loading data\n",
    "'''\n",
    "train_df = pd.read_csv('train.csv', encoding = \"ISO-8859-1\") \n",
    "demog_df = pd.read_csv('demog.csv', encoding = \"ISO-8859-1\") \n",
    "submission = pd.read_csv('submission.csv', encoding = \"ISO-8859-1\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.hist(np.sort(train_df['RL'].dropna().values))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.hist(np.sort(train_df['OLV'].dropna().values))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.hist(np.sort(train_df['RR'].dropna().values))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.hist(np.sort(train_df['DRT'].dropna().values))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.hist(np.sort(train_df['DMS'].dropna().values))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.hist(np.sort(train_df['OLA'].dropna().values))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "demog_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df = pd.merge(train_df, demog_df, on='HCP_ID', how='left')\n",
    "train_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df.isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df['gender'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df['gender'] = train_df['gender'].fillna('MALE')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import LabelEncoder\n",
    "lbl = LabelEncoder()\n",
    "\n",
    "train_df['Region'] = lbl.fit_transform(train_df['Region'])\n",
    "train_df['Value'] = lbl.fit_transform(train_df['Value'])\n",
    "train_df['gender'] = lbl.fit_transform(train_df['gender'])\n",
    "\n",
    "train_df.dtypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "Number of Null values in every column\n",
    "'''\n",
    "def get_number_of_null_entries(df, var):\n",
    "    return df[var].shape[0] - df[var].count()\n",
    "\n",
    "for x in train_df.columns:\n",
    "    print (x, end=\" \")\n",
    "    print (get_number_of_null_entries(train_df, x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def fill_na_function(data, output_col):\n",
    "    predictor_cols = data.columns.drop(output_col)\n",
    "    null_indices = data[data[output_col].isnull()].index\n",
    "    non_null_indices = data[~(data[output_col].isnull())].index\n",
    "    \n",
    "    for col in predictor_cols:\n",
    "        if data[col].dtype=='object':\n",
    "            data[col] = data[col].fillna(data[col].mode()[0])\n",
    "        else:\n",
    "            data[col] = data[col].fillna(data[col].mean())\n",
    "    \n",
    "    for col in predictor_cols:\n",
    "        if(data[col].dtype == 'object'):\n",
    "            lbl = LabelEncoder().fit(data[col])\n",
    "            data[col] = lbl.transform(data[col])\n",
    "    \n",
    "    X, y = data[predictor_cols], data[output_col]\n",
    "    X_train, X_test = X.loc[non_null_indices], X.loc[null_indices]\n",
    "    y_train, y_test = y[non_null_indices], y[null_indices]\n",
    "    \n",
    "    if data[output_col].dtype == 'object':\n",
    "        num_class = len(np.unique(y_train))\n",
    "        if(num_class > 2):\n",
    "            xgb_model = xgb.XGBClassifier(objective = 'multi:softmax', num_class = num_class)\n",
    "            parameters = {\n",
    "              'learning_rate': [0.05],\n",
    "              'max_depth': [3,4,5,6],\n",
    "              'n_estimators': [30, 40, 50],\n",
    "            }\n",
    "            clf = GridSearchCV(xgb_model, parameters, n_jobs=5, cv=StratifiedKFold(n_splits=5, shuffle=True),verbose=10)\n",
    "            clf.fit(X_train, y_train)\n",
    "    \n",
    "            predicting_model = xgb.XGBClassifier(\n",
    "              objective = 'multi:softmax',\n",
    "              num_class = num_class,\n",
    "              learning_rate = clf.best_params_['learning_rate'],\n",
    "              max_depth = clf.best_params_['max_depth'],\n",
    "              n_estimators = clf.best_params_['n_estimators'],\n",
    "            )\n",
    "        else:\n",
    "            xgb_model = xgb.XGBClassifier()\n",
    "            parameters = {\n",
    "              'learning_rate': [0.05],\n",
    "              'max_depth': [3,4,5,6],\n",
    "              'n_estimators': [30, 60, 90, 125],\n",
    "            }\n",
    "            clf = GridSearchCV(xgb_model, parameters, n_jobs=5, cv=StratifiedKFold(n_splits=5, shuffle=True),verbose=10)\n",
    "            clf.fit(X_train, y_train)\n",
    "    \n",
    "            predicting_model = xgb.XGBClassifier(\n",
    "              learning_rate = clf.best_params_['learning_rate'],\n",
    "              max_depth = clf.best_params_['max_depth'],\n",
    "              n_estimators = clf.best_params_['n_estimators'],\n",
    "            )\n",
    "        predicting_model.fit(X_train, y_train)\n",
    "        y[null_indices] = predicting_model.predict(X_test)\n",
    "        return y\n",
    "    \n",
    "    else:\n",
    "        xgb_model = xgb.XGBRegressor()\n",
    "        parameters = {\n",
    "              'learning_rate': [0.05],\n",
    "              'max_depth': [3,4,5,6],\n",
    "              'n_estimators': [30, 60, 90, 125],\n",
    "        }\n",
    "        clf = GridSearchCV(xgb_model, parameters, n_jobs=5, cv=KFold(n_splits=5, shuffle=True), verbose=1)\n",
    "        clf.fit(X_train, y_train)\n",
    "        \n",
    "        predicting_model = xgb.XGBRegressor(\n",
    "              learning_rate = clf.best_params_['learning_rate'],\n",
    "              max_depth = clf.best_params_['max_depth'],\n",
    "              n_estimators = clf.best_params_['n_estimators'],\n",
    "        )\n",
    "        predicting_model.fit(X_train, y_train)\n",
    "        y[null_indices] = predicting_model.predict(X_test)\n",
    "        return y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "temp = pd.DataFrame(np.column_stack([train_df.columns, train_df.isnull().sum()]), columns = ['features', 'missing_values']).sort_values('missing_values')\n",
    "for col in temp['features']:\n",
    "    print (col, train_df[col].isnull().sum())\n",
    "    if (train_df[col].isnull().sum() !=0 ):\n",
    "        train_df[col] = fill_na_function(train_df.copy(), col)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df[['HCP_ID','RL', 'P2P', 'OLV', 'RR', 'DRT', 'DMS', 'OLA', 'DEM']].to_csv('shariq_suhail_03021997.csv', index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
